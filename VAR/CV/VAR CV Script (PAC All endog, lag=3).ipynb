{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from statsmodels.tsa.api import VAR, DynamicVAR, VARMAX\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.holtwinters import Holt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from pyramid.arima import auto_arima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal MASE script\n",
    "# Define seasonality as 12 (monthly data) in argument when ground truth data includes at least 24 months\n",
    "\n",
    "def seasonal_MASE(truth, forecast, seasonality=1):    \n",
    "    period = truth.shape[0] # T\n",
    "    # print(period)\n",
    "    forecast_errors = np.abs(truth - forecast)\n",
    "    # print(forecast_errors)\n",
    "    mean_absolute_forecast_error = np.sum(forecast_errors) / period\n",
    "    # print(mean_absolute_forecast_error)\n",
    "\n",
    "    naive_period = truth.shape[0] - seasonality # T - m\n",
    "    # print(naive_period)\n",
    "    # print(truth[seasonality:])\n",
    "    # print(truth[:period - seasonality])\n",
    "    naive_errors = np.abs(truth[seasonality:] - truth[:period - seasonality])\n",
    "    mean_absolute_naive_error = np.sum(naive_errors) / naive_period\n",
    "    \n",
    "    return mean_absolute_forecast_error / mean_absolute_naive_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nights = pd.read_csv('/Users/jinny/Documents/touristcast/datasets/nights_2010-2017.csv', index_col='date', parse_dates=['date'], \n",
    "                          usecols=[*range(1, 15)])\n",
    "temp = pd.read_csv('/Users/jinny/Documents/touristcast/datasets/avgtemp_2010-2017.csv',parse_dates=['date'],index_col='date',usecols=[*range(1, 15)])\n",
    "daysoff = pd.read_csv('/Users/jinny/Documents/touristcast/datasets/daysoff_2010-2017.csv',parse_dates=['date'],index_col='date',usecols=['date','daysoff'])\n",
    "gdp = pd.read_csv('/Users/jinny/Documents/touristcast/datasets/regionalGDP_2010-2015.csv',parse_dates=['date'],index_col='date',usecols=[*range(1, 15)])\n",
    "\n",
    "# df with data for training set\n",
    "data_PAC = pd.concat([nights, temp, daysoff, gdp], axis=1)\n",
    "data_PAC = data_PAC.dropna()\n",
    "data_PAC = data_PAC[['nights_PAC','avgtemp_PAC','gdp_PAC','daysoff']]\n",
    "\n",
    "# df with nights only for testing set\n",
    "nights_PAC = nights[['nights_PAC']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationarity + Seasonality\n",
    "- **Do checks apart** using scripts written before (see previous VAR tests)\n",
    "- See if series already stationary: If not stationary, do seasonal_decompose\n",
    "- Seasonality: Multiplicative or Additive\n",
    "- Adjust according in 'for' loop below (seasonal_decompose step + forecast step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gigantic CV 'for' loop\n",
    "1. Create train and test datasets (+ formatting for later)\n",
    "2. Seasonal decompose\n",
    "3. Predictions for: \n",
    "    - Seasonal (copypaste of last year)\n",
    "    - Trend (Holt)\n",
    "    - Residuals (VAR)\n",
    "4. Recompose for forecast\n",
    "5. Calculated error per CV step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Years of training data: ['2010', '2011']\n",
      "Predicted year: 2012-01-01\n",
      "VAR lag order: 3\n",
      "RMSE test: 104.43265967719107\n",
      "MAE test: 94.37319052195699\n",
      "-------\n",
      "Years of training data: ['2010', '2011', '2012']\n",
      "Predicted year: 2013-01-01\n",
      "VAR lag order: 3\n",
      "RMSE test: 110.45073857083092\n",
      "MAE test: 82.60564105445503\n",
      "-------\n",
      "Years of training data: ['2010', '2011', '2012', '2013']\n",
      "Predicted year: 2014-01-01\n",
      "VAR lag order: 3\n",
      "RMSE test: 101.07616603350503\n",
      "MAE test: 76.42134629999482\n",
      "-------\n",
      "Years of training data: ['2010', '2011', '2012', '2013', '2014']\n",
      "Predicted year: 2015-01-01\n",
      "VAR lag order: 3\n",
      "RMSE test: 73.89593366831619\n",
      "MAE test: 57.44109927869453\n",
      "-------\n",
      "Years of training data: ['2010', '2011', '2012', '2013', '2014', '2015']\n",
      "Predicted year: 2016-01-01\n",
      "VAR lag order: 3\n",
      "RMSE test: 101.21931418133535\n",
      "MAE test: 85.34349859359948\n",
      "-------\n",
      "Years of training data: ['2010', '2011', '2012', '2013', '2014', '2015']\n",
      "Predicted year: 2017-01-01\n",
      "VAR lag order: 3\n",
      "RMSE test: 138.1658432249903\n",
      "MAE test: 111.5383133541771\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "# Make sure to fill these in for each region! Input data must have datetime as index\n",
    "\n",
    "input_data = data_PAC         # dataframe-type dataset\n",
    "target = nights_PAC           # dataframe-type dataset\n",
    "start_year = '2010-01-01'     # date as string\n",
    "\n",
    "for index in range(2012, 2018):\n",
    "    end_year = str(index)+'-01-01'\n",
    "    predict_year = str(index+1)+'-01-01'\n",
    "    \n",
    "    training_period = (input_data.index>=start_year)&(input_data.index<end_year) \n",
    "    testing_period = (target.index>=end_year)&(target.index<predict_year)\n",
    "    \n",
    "    train_data = input_data[training_period]\n",
    "    test_data = np.array(target[testing_period]) # Array format to calculate errors at the end\n",
    "    \n",
    "    \n",
    "    # --------Seasonal decompose----------\n",
    "    \n",
    "    # - IMPORTANT - Change model (multiplicative or additive) based on season type of nights\n",
    "    decomposed_data = seasonal_decompose(train_data, model='multiplicative')  \n",
    "\n",
    "    seasonal_data = decomposed_data.seasonal.dropna()\n",
    "    trend_data = decomposed_data.trend.dropna()\n",
    "    residual_data = decomposed_data.resid.dropna()\n",
    "    \n",
    "    # ---------Seasonal prediction (Same as last year of training data)---------\n",
    "\n",
    "    # Duplicate last year's seasonal data\n",
    "    seasonal_forecast = seasonal_data[(seasonal_data.index>=start_year)&(seasonal_data.index<end_year)]\n",
    "    \n",
    "    # Forecasted DF without datetime index and only 12 months to be able to recompose later\n",
    "    # - IMPORTANT - Replace nights_PAC below with column name for your region\n",
    "    seasonal_forecast_df = pd.DataFrame(seasonal_forecast.nights_PAC.values[-12:])\n",
    "    \n",
    "    # --------Trend prediction (Linear Holt)----------\n",
    "    \n",
    "    # Holt model (w/ optimized fit) on nights\n",
    "    # - IMPORTANT - Replace nights_PAC below with column name for your region\n",
    "    trend_model = Holt(trend_data.nights_PAC).fit(optimized=True)\n",
    "    \n",
    "    # Predict 12 months of trend\n",
    "    trend_forecast = trend_model.predict(start=0, end=11)\n",
    "    \n",
    "    # Forecasted DF without datetime index to be able to recompose later\n",
    "    trend_forecast_df = pd.DataFrame(trend_forecast.values) \n",
    "    \n",
    "    # --------Residual prediction (VAR)----------\n",
    "\n",
    "    # VAR model: Don't use maxlags, use specific lags in fit argument below\n",
    "    resid_model = VAR(residual_data, dates=residual_data.index)\n",
    "    # - IMPORTANT - Replace lag number in fit below with desired lags\n",
    "    resid_results = resid_model.fit(3)\n",
    "    \n",
    "    lag_order = resid_results.k_ar\n",
    "\n",
    "    # Forecasted DF without datetime index to be able to recompose later\n",
    "    resid_forecast_df = pd.DataFrame(resid_results.forecast(residual_data.values[-lag_order:], 12))\n",
    "\n",
    "    # --------Recomposing results----------\n",
    "    # - IMPORTANT - Addition if additive series /// Multiplication if multiplicative series\n",
    "    forecast = seasonal_forecast_df[0] * trend_forecast_df[0] * resid_forecast_df[0]\n",
    "    \n",
    "    \n",
    "    # --------Calculated error measures for each CV step----------\n",
    "    rmse_test = np.sqrt(mean_squared_error(test_data, forecast))\n",
    "    mae_test = mean_absolute_error(test_data, forecast)\n",
    "    \n",
    "    print('Years of training data:', train_data.index.strftime('%Y').unique().tolist())\n",
    "    print('Predicted year:', end_year)\n",
    "    print('VAR lag order:', lag_order)\n",
    "    print('RMSE test:', rmse_test)\n",
    "    print('MAE test:', mae_test)\n",
    "    print('-------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
